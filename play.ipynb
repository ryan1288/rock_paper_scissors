{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rock Paper Scissors with Jetbot - Play!\n",
    "\n",
    "Use the trained model to detect whether the player's *action* is ``rock``, ``paper`` or ``scissor`` to calculate game reuslts and statistics.\n",
    "\n",
    "Make jetbot perform actions to indicate when the player should perform the *action*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialization\n",
    "* torch - PyTorch\n",
    "* functional - common NN functions\n",
    "* torchvision - popular datasets, architectures, and image transformations\n",
    "* cv2 - OpenCV2\n",
    "* numpy - numpy array data type\n",
    "* time - sleep() to control approximate update frequency\n",
    "* Robot - control motion motion\n",
    "* widgets - create an interactable or displayable interface in the notebook\n",
    "* Camera - interact with the camera onboard the jetbot\n",
    "* display - stream the live video feed\n",
    "* dlink - link and transform the data type\n",
    "* randrange - generate pseudorandom action for robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Robot\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "from IPython.display import display\n",
    "from traitlets import dlink\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Trained Model\n",
    "Create an identical model as the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load weights from ``rps_model.pth``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('rps_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer weights to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Preprocessing Function\n",
    "\n",
    "We have now loaded our model, but there's a slight issue.  The format that we trained our model doesnt *exactly* match the format of the camera.  To do that, \n",
    "we need to do some *preprocessing*.  This involves the following steps\n",
    "\n",
    "1. Convert from BGR to RGB\n",
    "2. Convert from HWC layout to CHW layout\n",
    "3. Normalize using same parameters as we did during training (our camera provides values in [0, 255] range and training loaded images in [0, 1] range so we need to scale by 255.0\n",
    "4. Transfer the data from CPU memory to GPU memory\n",
    "5. Add a batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the camera using widgets and use a slider to display the probability of the detected action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera.instance(width=224, height=224)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "rock_slider = widgets.FloatSlider(description='rock', min=0.0, max=1.0, orientation='vertical')\n",
    "paper_slider = widgets.FloatSlider(description='paper', min=0.0, max=1.0, orientation='vertical')\n",
    "scissor_slider = widgets.FloatSlider(description='scissor', min=0.0, max=1.0, orientation='vertical')\n",
    "win_rate_slider = widgets.FloatSlider(description='win rate', min=0.0, max=1.0, orientation='vertical')\n",
    "draw_rate_slider = widgets.FloatSlider(description='draw rate', min=0.0, max=1.0, orientation='vertical')\n",
    "lose_rate_slider = widgets.FloatSlider(description='lose rate', min=0.0, max=1.0, orientation='vertical')\n",
    "\n",
    "camera_link = dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(widgets.HBox([image, rock_slider, paper_slider, scissor_slider, win_rate_slider, draw_rate_slider, lose_rate_slider]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also create our robot instance which we'll need to drive the motors.\n",
    "Initialize variables to collect statistics and determine robot's state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = Robot()\n",
    "state = 0\n",
    "num_win = 0\n",
    "num_draw = 0\n",
    "num_lose = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a function that will get called whenever the camera's value changes.  This function will do the following steps\n",
    "\n",
    "1. Pre-process the camera image\n",
    "2. Execute the neural network\n",
    "3. While the neural network output indicates we're blocked, we'll turn left, otherwise we go forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def update(change):\n",
    "    global rock_slider, paper_slider, scissor_slider, robot, state, num_win, num_draw, num_lose\n",
    "    if (state == 0 or state == 1):\n",
    "        robot.forward(0.3)\n",
    "        time.sleep(0.25)\n",
    "        robot.stop()\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        state = state + 1\n",
    "    elif (state == 2):\n",
    "        robot.forward(0.3)\n",
    "        time.sleep(0.25)\n",
    "        \n",
    "        x = change['new'] \n",
    "        x = preprocess(x)\n",
    "        y = model(x)\n",
    "\n",
    "        # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "        y = F.softmax(y, dim=1)\n",
    "\n",
    "        prob_rock = float(y.flatten()[0])\n",
    "        prob_paper = float(y.flatten()[1])\n",
    "        prob_scissor = float(y.flatten()[2])\n",
    "\n",
    "        rock_slider.value = prob_rock\n",
    "        paper_slider.value = prob_paper\n",
    "        scissor_slider.value = prob_scissor\n",
    "        \n",
    "        result = [prob_rock, prob_paper, prob_scissor]\n",
    "        most_prob = result.index(max(result))\n",
    "        robot_play = randrange(0,3)\n",
    "        \n",
    "        if (most_prob == robot_play):\n",
    "            num_draw = num_draw + 1\n",
    "        elif ((most_prob - robot_play) % 3) == 1):\n",
    "            num_win = num_win + 1\n",
    "        elif ((most_prob - robot_play) % 3) == 2):\n",
    "            num_lose = num_lose + 1\n",
    "        \n",
    "        total_games = num_win + num_draw + num_lose\n",
    "        win_rate = num_win / total_games\n",
    "        draw_rate = num_draw / total_games\n",
    "        lose_rate = num_lose / total_games\n",
    "        \n",
    "        win_rate_slider.value = win_rate\n",
    "        draw_rate_slider.value = draw_rate\n",
    "        lose_rate_slider.value = lose_rate\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "        robot.stop()\n",
    "        \n",
    "        state = state + 1\n",
    "    elif (state == 3):\n",
    "        state = 0\n",
    "        time.sleep(2)\n",
    "    \n",
    "        \n",
    "update({'new': camera.value})  # we call the function once to intialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We've created our neural network execution function, but now we need to attach it to the camera for processing. \n",
    "\n",
    "We accomplish that with the ``observe`` function.\n",
    "\n",
    "> WARNING: This code will move the robot!! Please make sure your robot has clearance.  The collision avoidance should work, but the neural\n",
    "> network is only as good as the data it's trained on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(update, names='value')  # this attaches the 'update' function to the 'value' traitlet of our camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! If your robot is plugged in it should now be generating new commands with each new camera frame.  Perhaps start by placing your robot on the ground and seeing what it does when it reaches an obstacle.\n",
    "\n",
    "If you want to stop this behavior, you can unattach this callback by executing the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "camera.unobserve(update, names='value')\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps you want the robot to run without streaming video to the browser.  You can unlink the camera as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.unlink()  # don't stream to browser (will still run camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue streaming call the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.link()  # stream to browser (wont run camera)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
